#!/usr/bin/env python3
"""
Local Mock Server Œ≥ŒπŒ± Serverless RAG
ŒïœÄŒπœÑœÅŒ≠œÄŒµŒπ œÑŒøœÄŒπŒ∫œå testing œáœâœÅŒØœÇ AWS deployment.

Serverless RAG Project - MSc Thesis
"""

import os
import sys
import json
import time
import hashlib
from pathlib import Path
from typing import List, Dict, Any

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from flask import Flask, request, jsonify
    from flask_cors import CORS
except ImportError:
    print("Installing required packages...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install",
                          "flask", "flask-cors", "--break-system-packages", "-q"])
    from flask import Flask, request, jsonify
    from flask_cors import CORS

# =============================================================================
# Configuration
# =============================================================================

app = Flask(__name__)
CORS(app)

# Sample document chunks (simulating vector DB)
SAMPLE_CHUNKS = [
    {
        "id": "benefits_001",
        "text": "Œó TechCorp Hellas œÄœÅŒøœÉœÜŒ≠œÅŒµŒπ 25 Œ∑ŒºŒ≠œÅŒµœÇ Œ∫Œ±ŒΩŒøŒΩŒπŒ∫ŒÆœÇ Œ¨Œ¥ŒµŒπŒ±œÇ Œ≥ŒπŒ± ŒµœÅŒ≥Œ±Œ∂œåŒºŒµŒΩŒøœÖœÇ ŒºŒµ 0-5 Œ≠œÑŒ∑ œÄœÅŒøœãœÄŒ∑œÅŒµœÉŒØŒ±œÇ, 26 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 6-10 Œ≠œÑŒ∑, 27 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 11-15 Œ≠œÑŒ∑, Œ∫Œ±Œπ 30 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 21+ Œ≠œÑŒ∑.",
        "metadata": {"source": "benefits_guide.md", "section": "ŒÜŒ¥ŒµŒπŒµœÇ"},
        "embedding": None
    },
    {
        "id": "benefits_002",
        "text": "ŒëŒΩŒ±œÅœÅœâœÑŒπŒ∫ŒÆ Œ¨Œ¥ŒµŒπŒ±: 15 Œ∑ŒºŒ≠œÅŒµœÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, ŒµœÄŒπœÄŒªŒ≠ŒøŒΩ 15 Œ∑ŒºŒ≠œÅŒµœÇ ŒºŒµ ŒºŒπœÉŒ≠œÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ. ŒôŒ±œÑœÅŒπŒ∫ŒÆ Œ≤ŒµŒ≤Œ±ŒØœâœÉŒ∑ Œ±œÄŒ±ŒπœÑŒµŒØœÑŒ±Œπ Œ≥ŒπŒ± Œ±œÄŒøœÖœÉŒØŒ± Œ¨ŒΩœâ œÑœâŒΩ 3 Œ∑ŒºŒµœÅœéŒΩ.",
        "metadata": {"source": "benefits_guide.md", "section": "ŒëŒΩŒ±œÅœÅœâœÑŒπŒ∫ŒÆ ŒÜŒ¥ŒµŒπŒ±"},
        "embedding": None
    },
    {
        "id": "benefits_003",
        "text": "ŒìŒøŒΩŒπŒ∫ŒÆ Œ¨Œ¥ŒµŒπŒ±: ŒúŒ∑œÑœÅœåœÑŒ∑œÑŒ± 17 ŒµŒ≤Œ¥ŒøŒºŒ¨Œ¥ŒµœÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, Œ†Œ±œÑœÅœåœÑŒ∑œÑŒ± 14 Œ∑ŒºŒ≠œÅŒµœÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, ŒìŒøŒΩŒπŒ∫ŒÆ Œ±ŒΩŒ±œÑœÅŒøœÜŒÆœÇ 4 ŒºŒÆŒΩŒµœÇ œáœâœÅŒØœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ Œ≠œâœÇ 8 ŒµœÑœéŒΩ œÑŒ≠Œ∫ŒΩŒøœÖ.",
        "metadata": {"source": "benefits_guide.md", "section": "ŒìŒøŒΩŒπŒ∫ŒÆ ŒÜŒ¥ŒµŒπŒ±"},
        "embedding": None
    },
    {
        "id": "benefits_004",
        "text": "Œ•Œ≥ŒµŒπŒøŒΩŒøŒºŒπŒ∫ŒÆ Œ∫Œ¨ŒªœÖœàŒ∑ œÄŒµœÅŒπŒªŒ±ŒºŒ≤Œ¨ŒΩŒµŒπ ŒΩŒøœÉŒ∑ŒªŒµŒØŒ± Œ≠œâœÇ ‚Ç¨50.000, œáŒµŒπœÅŒøœÖœÅŒ≥ŒµŒØŒ± Œ≠œâœÇ ‚Ç¨30.000, Œ¥ŒπŒ±Œ≥ŒΩœâœÉœÑŒπŒ∫Œ¨ Œ≠œâœÇ ‚Ç¨5.000, œÜŒ¨œÅŒºŒ±Œ∫Œ± Œ≠œâœÇ ‚Ç¨3.000 ŒµœÑŒ∑œÉŒØœâœÇ. Œ†Œ¨œÅŒøœáŒøœÇ: Interamerican Group Health.",
        "metadata": {"source": "benefits_guide.md", "section": "Œ•Œ≥ŒµŒπŒøŒΩŒøŒºŒπŒ∫ŒÆ ŒöŒ¨ŒªœÖœàŒ∑"},
        "embedding": None
    },
    {
        "id": "security_001",
        "text": "ŒöœâŒ¥ŒπŒ∫ŒøŒØ œÄœÅœåœÉŒ≤Œ±œÉŒ∑œÇ: ŒïŒªŒ¨œáŒπœÉœÑŒø 12 œáŒ±œÅŒ±Œ∫œÑŒÆœÅŒµœÇ, œÑŒøœÖŒªŒ¨œáŒπœÉœÑŒøŒΩ 1 Œ∫ŒµœÜŒ±ŒªŒ±ŒØŒø, 1 œÄŒµŒ∂œå, 1 Œ±œÅŒπŒ∏ŒºœåœÇ, 1 ŒµŒπŒ¥ŒπŒ∫œåœÇ œáŒ±œÅŒ±Œ∫œÑŒÆœÅŒ±œÇ. ŒëŒªŒªŒ±Œ≥ŒÆ Œ∫Œ¨Œ∏Œµ 90 Œ∑ŒºŒ≠œÅŒµœÇ. ŒëœÄŒ±Œ≥ŒøœÅŒµœçŒµœÑŒ±Œπ Œ∑ Œ∫ŒøŒπŒΩŒøœÄŒøŒØŒ∑œÉŒ∑ œÉŒµ œÑœÅŒØœÑŒøœÖœÇ.",
        "metadata": {"source": "it_security_policy.md", "section": "ŒöœâŒ¥ŒπŒ∫ŒøŒØ"},
        "embedding": None
    },
    {
        "id": "security_002",
        "text": "MFA ŒµŒØŒΩŒ±Œπ œÖœÄŒøœáœÅŒµœâœÑŒπŒ∫œå Œ≥ŒπŒ± email, VPN, cloud ŒµœÜŒ±œÅŒºŒøŒ≥Œ≠œÇ (AWS, GCP, Azure), HR systems, Œ∫Œ±Œπ financial systems. ŒïŒ≥Œ∫ŒµŒ∫œÅŒπŒºŒ≠ŒΩŒµœÇ ŒºŒ≠Œ∏ŒøŒ¥ŒøŒπ: Microsoft Authenticator, Google Authenticator, Hardware tokens.",
        "metadata": {"source": "it_security_policy.md", "section": "MFA"},
        "embedding": None
    },
    {
        "id": "security_003",
        "text": "Œ£Œµ œÄŒµœÅŒØœÄœÑœâœÉŒ∑ Œ±œÄœéŒªŒµŒπŒ±œÇ/Œ∫ŒªŒøœÄŒÆœÇ œÉœÖœÉŒ∫ŒµœÖŒÆœÇ: 1) ŒëŒΩŒ±œÜŒøœÅŒ¨ œÉœÑŒø IT Help Desk ŒµŒΩœÑœåœÇ 1 œéœÅŒ±œÇ, 2) Remote wipe, 3) ŒëŒªŒªŒ±Œ≥ŒÆ œåŒªœâŒΩ œÑœâŒΩ Œ∫œâŒ¥ŒπŒ∫œéŒΩ, 4) ŒëŒΩŒ±œÜŒøœÅŒ¨ œÉœÑŒ∑ŒΩ Œ±œÉœÜŒ¨ŒªŒµŒπŒ± Œ±ŒΩ œÄŒµœÅŒπŒ≠œáŒµŒπ ŒµœÖŒ±ŒØœÉŒ∏Œ∑œÑŒ± Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ±.",
        "metadata": {"source": "it_security_policy.md", "section": "ŒëœÄœéŒªŒµŒπŒ± Œ£œÖœÉŒ∫ŒµœÖŒÆœÇ"},
        "embedding": None
    },
    {
        "id": "policy_001",
        "text": "Œ§Œ∑ŒªŒµœÅŒ≥Œ±œÉŒØŒ±: ŒïœÄŒπœÑœÅŒ≠œÄŒµœÑŒ±Œπ Œ≠œâœÇ 3 Œ∑ŒºŒ≠œÅŒµœÇ/ŒµŒ≤Œ¥ŒøŒºŒ¨Œ¥Œ± ŒºŒµ Œ≠Œ≥Œ∫œÅŒπœÉŒ∑ manager. ŒëœÄŒ±ŒπœÑŒµŒØœÑŒ±Œπ œÉœÑŒ±Œ∏ŒµœÅŒÆ œÉœçŒΩŒ¥ŒµœÉŒ∑ internet, œáœÅŒÆœÉŒ∑ VPN, Œ∫Œ±Œπ Œ¥ŒπŒ±Œ∏ŒµœÉŒπŒºœåœÑŒ∑œÑŒ± Œ∫Œ±œÑŒ¨ œÑŒπœÇ œéœÅŒµœÇ ŒµœÅŒ≥Œ±œÉŒØŒ±œÇ.",
        "metadata": {"source": "company_policy.md", "section": "Œ§Œ∑ŒªŒµœÅŒ≥Œ±œÉŒØŒ±"},
        "embedding": None
    },
    {
        "id": "policy_002",
        "text": "ŒëŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑ Œ±œÄœåŒ¥ŒøœÉŒ∑œÇ: ŒîŒπŒµŒΩŒµœÅŒ≥ŒµŒØœÑŒ±Œπ Œ¥œçŒø œÜŒøœÅŒ≠œÇ ŒµœÑŒ∑œÉŒØœâœÇ (ŒôŒøœçŒΩŒπŒøœÇ Œ∫Œ±Œπ ŒîŒµŒ∫Œ≠ŒºŒ≤œÅŒπŒøœÇ). Œ†ŒµœÅŒπŒªŒ±ŒºŒ≤Œ¨ŒΩŒµŒπ Œ±œÖœÑŒøŒ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑, Œ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑ Œ±œÄœå manager, Œ∫Œ±Œπ œÉœÖŒ∂ŒÆœÑŒ∑œÉŒ∑ œÉœÑœåœáœâŒΩ.",
        "metadata": {"source": "company_policy.md", "section": "ŒëŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑"},
        "embedding": None
    },
    {
        "id": "benefits_005",
        "text": "Ticket Restaurant Œ±ŒæŒØŒ±œÇ ‚Ç¨8/Œ∑ŒºŒ≠œÅŒ± ŒµœÅŒ≥Œ±œÉŒØŒ±œÇ ŒºŒµ Œ∫Œ¨œÅœÑŒ± Sodexo, Œ±œÄŒøŒ¥ŒµŒ∫œÑŒ¨ œÉŒµ 30.000+ œÉŒ∑ŒºŒµŒØŒ±. ŒïœÄŒπŒ¥œåœÑŒ∑œÉŒ∑ ŒºŒµœÑŒ±Œ∫ŒØŒΩŒ∑œÉŒ∑œÇ ‚Ç¨100/ŒºŒÆŒΩŒ± Œ≥ŒπŒ± ŒúŒúŒú ŒÆ parking.",
        "metadata": {"source": "benefits_guide.md", "section": "ŒüŒπŒ∫ŒøŒΩŒøŒºŒπŒ∫Œ≠œÇ Œ†Œ±œÅŒøœáŒ≠œÇ"},
        "embedding": None
    },
]

# Simple keyword-based search (simulating vector similarity)
def simple_search(query: str, top_k: int = 5) -> List[Dict]:
    """Simple keyword search to simulate vector similarity"""
    query_words = set(query.lower().split())

    scored_chunks = []
    for chunk in SAMPLE_CHUNKS:
        chunk_words = set(chunk["text"].lower().split())
        # Simple Jaccard-like similarity
        intersection = len(query_words & chunk_words)
        union = len(query_words | chunk_words)
        score = intersection / union if union > 0 else 0

        # Boost exact phrase matches
        if any(word in chunk["text"].lower() for word in query_words if len(word) > 3):
            score += 0.2

        scored_chunks.append((chunk, score))

    # Sort by score and return top_k
    scored_chunks.sort(key=lambda x: x[1], reverse=True)
    return [
        {
            "text": chunk["text"],
            "score": score,
            "metadata": chunk["metadata"]
        }
        for chunk, score in scored_chunks[:top_k]
        if score > 0
    ]

def generate_answer(query: str, contexts: List[Dict]) -> str:
    """Generate a mock answer based on retrieved contexts"""
    if not contexts:
        return "ŒîŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œ±ŒΩ œÉœáŒµœÑŒπŒ∫Œ≠œÇ œÄŒªŒ∑œÅŒøœÜŒøœÅŒØŒµœÇ œÉœÑŒ∑ Œ≤Œ¨œÉŒ∑ Œ≥ŒΩœéœÉŒ∑œÇ."

    # Build context string
    context_text = "\n".join([c["text"] for c in contexts[:3]])

    # Simple rule-based response (simulating LLM)
    query_lower = query.lower()

    if "Œ¨Œ¥ŒµŒπŒ±" in query_lower or "Œ¨Œ¥ŒµŒπŒµœÇ" in query_lower:
        if "Œ±ŒΩŒ±œÅœÅœâœÑŒπŒ∫ŒÆ" in query_lower:
            return "Œ£œçŒºœÜœâŒΩŒ± ŒºŒµ œÑŒ∑ŒΩ œÄŒøŒªŒπœÑŒπŒ∫ŒÆ œÑŒ∑œÇ ŒµœÑŒ±ŒπœÅŒµŒØŒ±œÇ, Œ¥ŒπŒ∫Œ±ŒπŒøœçœÉœÑŒµ 15 Œ∑ŒºŒ≠œÅŒµœÇ Œ±ŒΩŒ±œÅœÅœâœÑŒπŒ∫ŒÆœÇ Œ¨Œ¥ŒµŒπŒ±œÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, Œ∫Œ±Œπ ŒµœÄŒπœÄŒªŒ≠ŒøŒΩ 15 Œ∑ŒºŒ≠œÅŒµœÇ ŒºŒµ ŒºŒπœÉŒ≠œÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ. ŒìŒπŒ± Œ±œÄŒøœÖœÉŒØŒ± Œ¨ŒΩœâ œÑœâŒΩ 3 Œ∑ŒºŒµœÅœéŒΩ Œ±œÄŒ±ŒπœÑŒµŒØœÑŒ±Œπ ŒπŒ±œÑœÅŒπŒ∫ŒÆ Œ≤ŒµŒ≤Œ±ŒØœâœÉŒ∑."
        elif "Œ≥ŒøŒΩŒπŒ∫ŒÆ" in query_lower or "ŒºŒ∑œÑœÅœåœÑŒ∑œÑŒ±" in query_lower:
            return "Œó ŒµœÑŒ±ŒπœÅŒµŒØŒ± œÄœÅŒøœÉœÜŒ≠œÅŒµŒπ: ŒÜŒ¥ŒµŒπŒ± ŒºŒ∑œÑœÅœåœÑŒ∑œÑŒ±œÇ 17 ŒµŒ≤Œ¥ŒøŒºŒ¨Œ¥ŒµœÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, Œ¨Œ¥ŒµŒπŒ± œÄŒ±œÑœÅœåœÑŒ∑œÑŒ±œÇ 14 Œ∑ŒºŒ≠œÅŒµœÇ ŒºŒµ œÄŒªŒÆœÅŒµŒπœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ, Œ∫Œ±Œπ Œ≥ŒøŒΩŒπŒ∫ŒÆ Œ¨Œ¥ŒµŒπŒ± Œ±ŒΩŒ±œÑœÅŒøœÜŒÆœÇ 4 ŒºŒ∑ŒΩœéŒΩ (œáœâœÅŒØœÇ Œ±œÄŒøŒ¥ŒøœáŒ≠œÇ) Œ≥ŒπŒ± œÄŒ±ŒπŒ¥ŒπŒ¨ Œ≠œâœÇ 8 ŒµœÑœéŒΩ."
        else:
            return "Œó Œ∫Œ±ŒΩŒøŒΩŒπŒ∫ŒÆ Œ¨Œ¥ŒµŒπŒ± ŒµŒæŒ±œÅœÑŒ¨œÑŒ±Œπ Œ±œÄœå œÑŒ± Œ≠œÑŒ∑ œÄœÅŒøœãœÄŒ∑œÅŒµœÉŒØŒ±œÇ: 25 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 0-5 Œ≠œÑŒ∑, 26 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 6-10 Œ≠œÑŒ∑, 27 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 11-15 Œ≠œÑŒ∑, 28 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 16-20 Œ≠œÑŒ∑, Œ∫Œ±Œπ 30 Œ∑ŒºŒ≠œÅŒµœÇ Œ≥ŒπŒ± 21+ Œ≠œÑŒ∑."

    elif "Œ∫œâŒ¥ŒπŒ∫" in query_lower or "password" in query_lower:
        return "Œó œÄŒøŒªŒπœÑŒπŒ∫ŒÆ Œ∫œâŒ¥ŒπŒ∫œéŒΩ Œ±œÄŒ±ŒπœÑŒµŒØ: ŒµŒªŒ¨œáŒπœÉœÑŒø 12 œáŒ±œÅŒ±Œ∫œÑŒÆœÅŒµœÇ, œÑŒøœÖŒªŒ¨œáŒπœÉœÑŒøŒΩ 1 Œ∫ŒµœÜŒ±ŒªŒ±ŒØŒø, 1 œÄŒµŒ∂œå, 1 Œ±œÅŒπŒ∏ŒºœåœÇ, Œ∫Œ±Œπ 1 ŒµŒπŒ¥ŒπŒ∫œåœÇ œáŒ±œÅŒ±Œ∫œÑŒÆœÅŒ±œÇ. ŒüŒπ Œ∫œâŒ¥ŒπŒ∫ŒøŒØ œÄœÅŒ≠œÄŒµŒπ ŒΩŒ± Œ±ŒªŒªŒ¨Œ∂ŒøœÖŒΩ Œ∫Œ¨Œ∏Œµ 90 Œ∑ŒºŒ≠œÅŒµœÇ Œ∫Œ±Œπ Œ±œÄŒ±Œ≥ŒøœÅŒµœçŒµœÑŒ±Œπ Œ∑ Œ∫ŒøŒπŒΩŒøœÄŒøŒØŒ∑œÉŒÆ œÑŒøœÖœÇ."

    elif "mfa" in query_lower or "authentication" in query_lower:
        return "Œ§Œø MFA (Multi-Factor Authentication) ŒµŒØŒΩŒ±Œπ œÖœÄŒøœáœÅŒµœâœÑŒπŒ∫œå Œ≥ŒπŒ±: email, VPN, cloud ŒµœÜŒ±œÅŒºŒøŒ≥Œ≠œÇ (AWS, GCP, Azure), HR systems, Œ∫Œ±Œπ financial systems. ŒïŒ≥Œ∫ŒµŒ∫œÅŒπŒºŒ≠ŒΩŒµœÇ ŒºŒ≠Œ∏ŒøŒ¥ŒøŒπ: Microsoft Authenticator (œÄœÅŒøœÑŒπŒºœéŒºŒµŒΩŒø), Google Authenticator, Œ∫Œ±Œπ Hardware tokens."

    elif "œÑŒ∑ŒªŒµœÅŒ≥Œ±œÉŒØŒ±" in query_lower or "remote" in query_lower:
        return "Œó œÑŒ∑ŒªŒµœÅŒ≥Œ±œÉŒØŒ± ŒµœÄŒπœÑœÅŒ≠œÄŒµœÑŒ±Œπ Œ≠œâœÇ 3 Œ∑ŒºŒ≠œÅŒµœÇ œÑŒ∑ŒΩ ŒµŒ≤Œ¥ŒøŒºŒ¨Œ¥Œ± ŒºŒµ Œ≠Œ≥Œ∫œÅŒπœÉŒ∑ œÑŒøœÖ manager. ŒëœÄŒ±ŒπœÑŒµŒØœÑŒ±Œπ œÉœÑŒ±Œ∏ŒµœÅŒÆ œÉœçŒΩŒ¥ŒµœÉŒ∑ internet, œáœÅŒÆœÉŒ∑ VPN Œ≥ŒπŒ± œÄœÅœåœÉŒ≤Œ±œÉŒ∑ œÉŒµ ŒµœÑŒ±ŒπœÅŒπŒ∫Œ¨ œÉœÖœÉœÑŒÆŒºŒ±œÑŒ±, Œ∫Œ±Œπ Œ¥ŒπŒ±Œ∏ŒµœÉŒπŒºœåœÑŒ∑œÑŒ± Œ∫Œ±œÑŒ¨ œÑŒπœÇ Œ∫Œ±ŒΩŒøŒΩŒπŒ∫Œ≠œÇ œéœÅŒµœÇ ŒµœÅŒ≥Œ±œÉŒØŒ±œÇ."

    elif "Œ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑" in query_lower or "Œ±œÄœåŒ¥ŒøœÉŒ∑" in query_lower:
        return "Œó Œ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑ Œ±œÄœåŒ¥ŒøœÉŒ∑œÇ Œ¥ŒπŒµŒΩŒµœÅŒ≥ŒµŒØœÑŒ±Œπ Œ¥œçŒø œÜŒøœÅŒ≠œÇ ŒµœÑŒ∑œÉŒØœâœÇ (ŒôŒøœçŒΩŒπŒøœÇ Œ∫Œ±Œπ ŒîŒµŒ∫Œ≠ŒºŒ≤œÅŒπŒøœÇ). Œó Œ¥ŒπŒ±Œ¥ŒπŒ∫Œ±œÉŒØŒ± œÄŒµœÅŒπŒªŒ±ŒºŒ≤Œ¨ŒΩŒµŒπ Œ±œÖœÑŒøŒ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑ œÑŒøœÖ ŒµœÅŒ≥Œ±Œ∂ŒøŒºŒ≠ŒΩŒøœÖ, Œ±ŒæŒπŒøŒªœåŒ≥Œ∑œÉŒ∑ Œ±œÄœå œÑŒøŒΩ manager, Œ∫Œ±Œπ œÉœÖŒ∂ŒÆœÑŒ∑œÉŒ∑ Œ≥ŒπŒ± œÑŒøœÖœÇ œÉœÑœåœáŒøœÖœÇ œÑŒ∑œÇ ŒµœÄœåŒºŒµŒΩŒ∑œÇ œÄŒµœÅŒπœåŒ¥ŒøœÖ."

    elif "Œ±œÉœÜŒ¨ŒªŒπ" in query_lower or "œÖŒ≥ŒµŒØ" in query_lower or "insurance" in query_lower:
        return "Œó œÖŒ≥ŒµŒπŒøŒΩŒøŒºŒπŒ∫ŒÆ Œ∫Œ¨ŒªœÖœàŒ∑ œÄŒµœÅŒπŒªŒ±ŒºŒ≤Œ¨ŒΩŒµŒπ: ŒΩŒøœÉŒ∑ŒªŒµŒØŒ± Œ≠œâœÇ ‚Ç¨50.000, œáŒµŒπœÅŒøœÖœÅŒ≥ŒµŒØŒ± Œ≠œâœÇ ‚Ç¨30.000, Œ¥ŒπŒ±Œ≥ŒΩœâœÉœÑŒπŒ∫Œ¨ Œ≠œâœÇ ‚Ç¨5.000, Œ∫Œ±Œπ œÜŒ¨œÅŒºŒ±Œ∫Œ± (80% Œ∫Œ¨ŒªœÖœàŒ∑) Œ≠œâœÇ ‚Ç¨3.000 ŒµœÑŒ∑œÉŒØœâœÇ. Œ†Œ¨œÅŒøœáŒøœÇ ŒµŒØŒΩŒ±Œπ Œ∑ Interamerican Group Health. ŒîœÖŒΩŒ±œÑœåœÑŒ∑œÑŒ± ŒµœÄŒ≠Œ∫œÑŒ±œÉŒ∑œÇ Œ≥ŒπŒ± œÉœçŒ∂œÖŒ≥Œø (+‚Ç¨80/ŒºŒÆŒΩŒ±) Œ∫Œ±Œπ œÄŒ±ŒπŒ¥ŒπŒ¨ (+‚Ç¨40/ŒºŒÆŒΩŒ±)."

    elif "ticket" in query_lower or "œÉŒØœÑŒπœÉŒ∑" in query_lower or "œÜŒ±Œ≥Œ∑œÑœå" in query_lower:
        return "Œó ŒµœÑŒ±ŒπœÅŒµŒØŒ± œÄŒ±œÅŒ≠œáŒµŒπ Ticket Restaurant Œ±ŒæŒØŒ±œÇ ‚Ç¨8 Œ±ŒΩŒ¨ Œ∑ŒºŒ≠œÅŒ± ŒµœÅŒ≥Œ±œÉŒØŒ±œÇ ŒºŒ≠œÉœâ Œ∫Œ¨œÅœÑŒ±œÇ Sodexo, Œ∑ ŒøœÄŒøŒØŒ± Œ≥ŒØŒΩŒµœÑŒ±Œπ Œ±œÄŒøŒ¥ŒµŒ∫œÑŒÆ œÉŒµ œÄŒµœÅŒπœÉœÉœåœÑŒµœÅŒ± Œ±œÄœå 30.000 œÉŒ∑ŒºŒµŒØŒ± œÄŒ±ŒΩŒµŒªŒªŒ±Œ¥ŒπŒ∫Œ¨."

    else:
        # Generic response using first context
        return f"ŒúŒµ Œ≤Œ¨œÉŒ∑ œÑŒπœÇ Œ¥ŒπŒ±Œ∏Œ≠œÉŒπŒºŒµœÇ œÄŒªŒ∑œÅŒøœÜŒøœÅŒØŒµœÇ: {contexts[0]['text']}"

# =============================================================================
# API Routes
# =============================================================================

@app.route("/", methods=["GET"])
def health():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "service": "Serverless RAG (Local Mock)",
        "version": "1.0.0",
        "mode": "development"
    })

@app.route("/query", methods=["POST"])
def query():
    """RAG Query endpoint"""
    start_time = time.time()

    data = request.get_json()
    if not data or "query" not in data:
        return jsonify({"error": "Missing 'query' field"}), 400

    query_text = data["query"]
    top_k = data.get("top_k", 5)

    # Simulate processing time
    time.sleep(0.1)

    # Search for relevant chunks
    search_start = time.time()
    results = simple_search(query_text, top_k)
    search_time = (time.time() - search_start) * 1000

    # Generate answer
    llm_start = time.time()
    answer = generate_answer(query_text, results)
    llm_time = (time.time() - llm_start) * 1000

    total_time = (time.time() - start_time) * 1000

    # Check for "cache hit" simulation (same query hash)
    query_hash = hashlib.md5(query_text.encode()).hexdigest()[:8]
    cache_hit = hasattr(app, '_last_query') and app._last_query == query_hash
    app._last_query = query_hash

    return jsonify({
        "query": query_text,
        "answer": answer,
        "sources": [
            {
                "filename": r["metadata"]["source"],
                "section": r["metadata"]["section"],
                "score": round(r["score"], 3),
                "text": r["text"][:200] + "..." if len(r["text"]) > 200 else r["text"]
            }
            for r in results
        ],
        "metrics": {
            "total_ms": round(total_time, 1),
            "search_ms": round(search_time, 1),
            "llm_ms": round(llm_time, 1),
            "cache_hit": cache_hit
        }
    })

@app.route("/ingest", methods=["POST"])
def ingest():
    """Mock ingestion endpoint"""
    data = request.get_json()
    if not data or "key" not in data:
        return jsonify({"error": "Missing 'key' field"}), 400

    # Simulate ingestion
    time.sleep(0.2)

    return jsonify({
        "status": "success",
        "message": f"Document '{data['key']}' queued for processing (mock)",
        "document_id": hashlib.md5(data["key"].encode()).hexdigest()[:12],
        "chunks_created": 5  # Mock value
    })

@app.route("/documents", methods=["GET"])
def list_documents():
    """List indexed documents"""
    unique_sources = set(chunk["metadata"]["source"] for chunk in SAMPLE_CHUNKS)
    return jsonify({
        "documents": [
            {"name": source, "chunks": sum(1 for c in SAMPLE_CHUNKS if c["metadata"]["source"] == source)}
            for source in unique_sources
        ],
        "total_chunks": len(SAMPLE_CHUNKS)
    })

# =============================================================================
# Main
# =============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Local RAG Mock Server")
    parser.add_argument("--host", default="127.0.0.1", help="Host to bind")
    parser.add_argument("--port", "-p", type=int, default=3000, help="Port to listen on")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode")

    args = parser.parse_args()

    print("\n" + "=" * 50)
    print("üöÄ Serverless RAG - Local Mock Server")
    print("=" * 50)
    print(f"\nüìç Server: http://{args.host}:{args.port}")
    print(f"üìö Indexed: {len(SAMPLE_CHUNKS)} chunks from {len(set(c['metadata']['source'] for c in SAMPLE_CHUNKS))} documents")
    print("\nüìã Endpoints:")
    print(f"   GET  /           - Health check")
    print(f"   POST /query      - RAG query")
    print(f"   POST /ingest     - Document ingestion (mock)")
    print(f"   GET  /documents  - List indexed documents")
    print("\nüí° Test with:")
    print(f"   python examples/api_client.py -e http://localhost:{args.port} -i")
    print("\n" + "-" * 50)
    print("Press Ctrl+C to stop\n")

    app.run(host=args.host, port=args.port, debug=args.debug)
